<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <script src="https://cdnjs.cloudflare.com/ajax/libs/wavesurfer.js/1.2.3/wavesurfer.min.js"></script>
    <script type="text/javascript" src="plugin/wavesurfer-regions.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/wavesurfer.js/1.2.3/plugin/wavesurfer.timeline.min.js"></script>
    <script src="https://code.jquery.com/jquery-1.10.2.js"></script>
    <link rel="stylesheet" href="css/index.css"> 

    <title>Instrument Recognition - Amy</title>
    <!--
    <style>
        #bg {
            background-image: url(img/guitar_bg.jpg);
            background-size: cover;
            background-repeat: no-repeat;
            background-attachment: fixed;
            background-position: center center;
            opacity: 0.2;
            height: 100vh;
            position: fixed;
            min-width: 100vw;
            z-index: -1;
            top: 0;
        }
    </style>-->
    <!-- load stylesheets -->
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:300,400">   <!-- Google web font "Open Sans" -->
    <link rel="stylesheet" href="css/bootstrap.min.css">                                      <!-- Bootstrap style -->
    <link rel="stylesheet" href="css/magnific-popup.css">                                     <!-- Magnific pop up style -->
    <link rel="stylesheet" href="css/templatemo-style.css">                                   <!-- Templatemo style -->

    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
        <!--[if lt IE 9]>
          <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
          <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
          <![endif]-->
      </head>

      <body>
        
        <div class="container">

            <div class="tm-sidebar">
                <nav class="tm-main-nav">
                    <ul>
                        <li class="tm-nav-item logo"><img src="img/logo.png" class="img-fluid tm-sidebar-image"></li>
                        <li class="tm-nav-item"><a href="#home" class="tm-nav-item-link">Home</a></li>
                        <li class="tm-nav-item"><a href="#abstract" class="tm-nav-item-link">Abstract</a></li>
                        <li class="tm-nav-item"><a href="#musicnet" class="tm-nav-item-link">Dataset</a></li>
                        <li class="tm-nav-item"><a href="#model" class="tm-nav-item-link">Model</a></li>
                        <li class="tm-nav-item"><a href="#result" class="tm-nav-item-link">Result</a></li>
                    </ul>
                </nav>
            </div>
            
            <div class="tm-main-content">
                
                <section id="home" class="tm-content-box tm-banner margin-b-10">
                    <div class="tm-banner-inner">
                        <h1 class="tm-banner-title">Frame-level Instrument Recognition by Timbre and Pitch</h1>
                        <br>
                        <p>Yun-Ning Hung and Yi-Hsuan Yang <br>
                            Music and Audio Computing Lab<br>
                            Research Center for IT innovation, Academia Sinica, Taipei, Taiwan</p>
                        <p>[<a href="https://github.com/biboamy/instrument-prediction">Github</a>]
                            [<a href="https://arxiv.org/abs/1806.09587">Paper</a>]
                            [<a href="https://musicai.citi.sinica.edu.tw/">MACLab</a>]
                            [<a href="https://biboamy.github.io/instrument-demo/source/amy-ismir2018-slide.pdf">Slide</a>]
                            [<a href="https://biboamy.github.io/instrument-demo/source/amy-ismir2018-poster.pdf">Poster</a>]</p>
                    </div>                    
                </section>

                <section>
                    <div id="abstract" class="tm-content-box">
                        <div class="pad flex-item tm-team-description-container">
                            <h2 class="tm-section-title">Abstract</h2>
                            <p>Instrument recognition is a fundamental task in music information
                                retrieval, yet little has been done to predict the
                                presence of instruments in multi-instrument music for each
                                time frame. This task is important for not only automatic
                                transcription but also many retrieval problems. In this paper,
                                we use the newly released MusicNet dataset to study
                                this front, by building and evaluating a convolutional neural
                                network for making frame-level instrument prediction.
                                We consider it as a multi-label classification problem for
                                each frame and use frame-level annotations as the supervisory
                                signal in training the network. Moreover, we experiment
                                with different ways to incorporate pitch information
                                to our model, with the premise that doing so informs the
                                model the notes that are active per frame, and also encourages
                                the model to learn relative rates of energy buildup
                                in the harmonic partials of different instruments. Experiments
                                show salient performance improvement over baseline
                                methods. We also report an analysis probing how pitch
                                information helps the instrument prediction task.</p>
                            
                        </div>
                    </div>
                </section>
                <section>
                    <div id="musicnet" class="tm-content-box">
                        <div class='container pad'>
                            <h2>MusicNet Dataset</h2>
                            <p>There are lots of instrument related dataset. However, few of them contain instrument frame labels. We chose MusicNet dataset for two reasons. 1) It's larger than other two dataset. 2) It contains pitch ground truth labels. </p>
                            <p>MusicNet dataset is a collection of 330 freely-licensed classical music recordings with pre-defined 320 recordings for training and 10 recordings for testing. To get the detailed information, please visit MusicNet <a href="https://homes.cs.washington.edu/~thickstn/musicnet.html">website</a>. Since pre-defined test set only contains seven instruments, we only include these instruments in our experiment, which are Piano, Violin, Viola, Cello, Clarinet, Bassoon, Horn. Each song is divided into 3 seconds chunks for training efficiency.</p> Song id used in this experiment can be downloaded here (<a href="https://github.com/biboamy/instrument-recognition/blob/master/trname.txt">train</a>/<a href="https://github.com/biboamy/instrument-recognition/blob/master/tename.txt.txt">test</a>)
                            <div align="center">
                                <div style="display: inline-block; width: 50%">
                                    <p style="margin-top: 50px">Instrument related dataset. </p>
                                    <img src="img/dataset_all.png" class="model_img" style=" width: 100%">
                                </div>
                                <div style="display: inline-block;width: 40%;margin-left: 50px">
                                    <p style="margin-top: 50px; ">MusicNet dataset statistic. </p>
                                    <img src="img/dataset_statistic.png" class="model_img" style=" width: 90%">
                                </div>
                            </div>
                        </div>
                    </div>
                    
                </section>

                <!-- slider -->
                <section id="model" class="tm-content-box">
                    <div class='container pad'>
                        <h2>Model Structure</h2>
                        <center>
                            <img src="img/JYnet.png" class="model_img" style="width: 20%">
                            <img src="img/SYnet.png" class="model_img" style="width: 30%">
                        </center>
                        <p style="margin-top: 50px">Two models used in this paper for training frame-level instrument annotations. Left one is adopted from <a href="http://mac.citi.sinica.edu.tw/~yang/pub/liu16mm.pdf">Liu et al.</a> and right one is adapted from <a href="https://www.ijcai.org/proceedings/2018/0463.pdf">Chou et al.</a> We don't modify the temporal dimension during convolusion since we want to preserve the temoral information. The models are trained based on frame-labels supervised learning.</p>

                        <h2>Input Feature</h2>
                        <center style="margin-top: 50px">
                            <img src="img/diff_input.png" class="model_img" style="width: 40%">
                            <img src="img/HS.png" class="model_img" style="width: 30%">
                        </center>
                        <p style="margin-top: 50px">We experiment on four kinds of input features: <br>
                            <i>Note that pitch source can be ground truth pitch or pitch estimated by estimator (<a href="https://arxiv.org/abs/1711.04845">Thickstun et al.</a>)</i>
                            <ul style="margin-left: 50px">
                                <li>CQT: Constant  Q transform (CQT) is extracted from input audio with 88 frequency bins (piano notes) and 258 time step</li>
                                <li>CQT+Pitch (C): Pitch is concatenated along channel dimension. .</li>
                                <li>CQT+Pitch (F): Pitch is concatenated along frequency dimension.</li>
                                <li>CQT+HSF: Harmonic series feature (HSF) is concatenated along channel dimension. HSF can be obtained by shifting fundamental frequency (pitch) upward to the harmonic series frequency. The intuition here is that since timbre is related to harmonic distribution, salient the harmonic frequencies can encourage the model to learn the harmonic distribution.</li>
                            </ul>
                        </p>

                        <h2>Output Instrument Roll</h2>
                        <p style="margin-top: 50px; width: 40%; display: inline-block;">
                        The output instrument roll is a 2D matrix. X dimension represents the time step while y dimension represent which instruments are active in this time frame. 
                        </p>
                        <img src="img/inst_roll.png" style=" width: 40%; display: inline-block;">

                    </div>                    
                </section>
                
                <section id="result" class="tm-content-box">
                    <div class='container pad'>
                        <h2>Result</h2>
                        Here shows the instrument frame-level recognition result trained on <a href="https://homes.cs.washington.edu/~thickstn/musicnet.html">MusicNet Dataset</a>. Result trained on Musescore Dataset can be found <a href="https://biboamy.github.io/instrument-recognition/demo.html">here.</a>
                        <div id='model_choose' style="padding-top: 20px;">
                            <select id="s_song">
                                <option value="hurt">Christina Aguilera - Hurt</option>
                                <option value="beau">Christina Aguilera - Beautiful</option>
                                <option value="ctu">Carpenters - Close to you</option>
                                <option value="says">A Great Big World Christina Aguilera - Say Something</option>
                                <option value="make_you">Adele - Make You Feel My Love</option>
                                <option value="halle">Hallelujah for violin and piano (COVER)</option>
                                <option value="slyc">Someone Like You Cover - Adele (CelloPiano) - Brooklyn Duo</option>
                                <option value="2628">MusicNet - 2628</option>
                                <option value="2556">MusicNet - 2556</option>
                                <option value="2416">MusicNet - 2416</option>
                                <option value="2382">MusicNet - 2382</option>
                                <option value="2303">MusicNet - 2303</option>
                                <option value="2298">MusicNet - 2298</option>
                                <option value="2191">MusicNet - 2191</option>
                                <option value="2106">MusicNet - 2106</option>
                                <option value="1819">MusicNet - 1819</option>
                            </select>
                            <button onclick="togglePlay()">Play/Pause</button>(It may take some times to process the audio. Please wait!)
                        </div>

                        <div id='button_block'>
                        <div class="left_region" id="label2" >
                            <p>Piano</p>
                            <p>Violin</p>
                            <p>Viola</p>
                            <p>Cello</p>
                            <p>Clarinet</p>
                            <p>Bassoon</p>
                            <p>Horn</p>
                        </div>
                        <div id='right_region'>
                            <div id="waveform-timeline"></div>
                            <div id="waveform"></div>
                        </div>
                    </div>
                </section>

            </div>
             
        </div>
        <div id="bg">
            
        </div>
        
        <!-- load JS files -->
        
        <script src="js/jquery-1.11.3.min.js"></script>             <!-- jQuery (https://jquery.com/download/) -->
        <script src="js/bootstrap.min.js"></script>                 <!-- Bootstrap (http://v4-alpha.getbootstrap.com/getting-started/download/) -->
        <script src="js/jquery.magnific-popup.min.js"></script>     <!-- Magnific pop-up (http://dimsemenov.com/plugins/magnific-popup/) -->
        <script src="js/jquery.singlePageNav.min.js"></script>      <!-- Single Page Nav (https://github.com/ChrisWojcik/single-page-nav) -->
        <script src="js/jquery.touchSwipe.min.js"></script>         <!-- https://github.com/mattbryson/TouchSwipe-Jquery-Plugin -->
        
        <!-- Templatemo scripts -->
        <script>                      
    
        $(document).ready(function(){

            // Single page nav
            if($(window).width() <= 1139) {
                $('.tm-main-nav').singlePageNav({
                    'currentClass' : "active",
                    offset : 100
                });
            } else {
                $('.tm-main-nav').singlePageNav({
                    'currentClass' : "active",
                    offset : 80
                });
            }

            // Handle nav offset upon window resize
            $(window).resize(function(){
                if($(window).width() <= 1139) {
                    $('.tm-main-nav').singlePageNav({
                        'currentClass' : "active",
                        offset : 100
                    });
                } else {
                    $('.tm-main-nav').singlePageNav({
                        'currentClass' : "active",
                        offset : 80
                    });
                }
            });

            // Magnific pop up
            $('.gallery-container').magnificPopup({
              delegate: 'a', // child items selector, by clicking on it popup will open
              type: 'image',
              gallery: {enabled:true}
              // other options
            });

            $('.carousel').carousel({
              interval: 3000
            })

            // Enable carousel swiping (http://lazcreative.com/blog/adding-swipe-support-to-bootstrap-carousel-3-0/)
            $(".carousel-inner").swipe( {
                //Generic swipe handler for all directions
                swipeLeft:function(event, direction, distance, duration, fingerCount) {
                    $(this).parent().carousel('next'); 
                },
                swipeRight: function() {
                    $(this).parent().carousel('prev'); 
                }
            });

        });

        var wavesurfer = WaveSurfer.create({
            container: '#waveform',
            waveColor: '#267CB9',
            progressColor: '#00008B',
        });

        load_song("hurt")

        $('#s_song').on('change', function() {
            load_song(this.value)
        })

        function togglePlay(){
            wavesurfer.playPause()
        }

        function load_song(song){
            name = song
            wavesurfer.load('mp3/'+song+'.mp3');
            wavesurfer.on('ready', function () {
                if (song==name){
                    console.log(song)
                    var timeline = Object.create(WaveSurfer.Timeline);
                    timeline.init({
                        wavesurfer: wavesurfer,
                        container: '#waveform-timeline'
                    });
                    
                    show_result("model1",song)
                }
            });
        }

        function show_result(model,name){
            
            wavesurfer.clearRegions()
            for (i = 0; i < 10; i++) { 
                (function(i) {
                    $.getJSON('json/'+model+'/'+name+'/'+i+'.json', function(data) {         
                        for (j in data) {
                            wavesurfer.addRegion({start: data[j]['start'], end: data[j]['end'], top: 140+i*40, color: 'hsla(0, 0%, 0%, 0.4)'});
                        }
                    });
                })(i);
            }
        }
        $( "wave" ).first().css( "height", 430 );
        </script>             

    </body>
    </html>
